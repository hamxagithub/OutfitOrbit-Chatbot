{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e2b6ff92",
   "metadata": {},
   "source": [
    "## üì¶ Step 1: Install Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88c7c713",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q gradio==4.44.0 sentence-transformers==3.0.1 faiss-cpu==1.8.0 \\\n",
    "    numpy==1.26.0 pillow==10.0.0 requests==2.31.0 transformers==4.35.0 \\\n",
    "    datasets==2.14.0 pandas==2.0.3 huggingface-hub==0.19.0 beautifulsoup4==4.12.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be7d4409",
   "metadata": {},
   "source": [
    "## üîß Step 2: Setup Configuration and Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bc67871",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gradio as gr\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import json\n",
    "import os\n",
    "import pickle\n",
    "import pandas as pd\n",
    "from typing import List, Dict, Tuple, Optional\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import faiss\n",
    "from datetime import datetime\n",
    "import logging\n",
    "from datasets import load_dataset\n",
    "from huggingface_hub import HfApi\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# Setup logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "logger = logging.getLogger(\"FashionAdvisor\")\n",
    "\n",
    "# Detect Colab environment\n",
    "try:\n",
    "    import google.colab\n",
    "    IN_COLAB = True\n",
    "    logger.info(\"‚úÖ Running in Google Colab\")\n",
    "    # Mount Google Drive for backup\n",
    "    from google.colab import drive\n",
    "    try:\n",
    "        drive.mount('/content/drive', force_remount=False)\n",
    "        logger.info(\"‚úÖ Google Drive mounted\")\n",
    "    except:\n",
    "        logger.warning(\"‚ö†Ô∏è Could not mount Drive, using local storage only\")\n",
    "    \n",
    "    SAVE_PATH = '/content/fashion_advisor_models'\n",
    "    BACKUP_PATH = '/content/drive/MyDrive/fashion_advisor_backup'\n",
    "except:\n",
    "    IN_COLAB = False\n",
    "    logger.info(\"Running locally\")\n",
    "    SAVE_PATH = './fashion_advisor_models'\n",
    "    BACKUP_PATH = './fashion_advisor_backup'\n",
    "\n",
    "# Create directories\n",
    "os.makedirs(SAVE_PATH, exist_ok=True)\n",
    "os.makedirs(BACKUP_PATH, exist_ok=True)\n",
    "\n",
    "# Configuration with anti-hallucination measures\n",
    "CONFIG = {\n",
    "    \"embedding_model\": \"sentence-transformers/all-MiniLM-L6-v2\",\n",
    "    \"top_k_retrieval\": 5,\n",
    "    \"enable_step_back\": True,\n",
    "    \"confidence_threshold\": 0.7,      # Higher = more conservative\n",
    "    \"min_relevance_score\": 0.5,       # Filter low-quality matches\n",
    "    \"max_context_docs\": 3,             # Limit context to prevent confusion\n",
    "    \"require_evidence\": True,          # Always cite sources\n",
    "    \"fallback_to_knowledge\": True      # Use curated knowledge if retrieval fails\n",
    "}\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"‚úÖ Configuration loaded\")\n",
    "print(f\"üìÅ Model save path: {SAVE_PATH}\")\n",
    "print(f\"üíæ Backup path: {BACKUP_PATH}\")\n",
    "print(f\"üõ°Ô∏è Anti-hallucination: ENABLED\")\n",
    "print(f\"üìä Confidence threshold: {CONFIG['confidence_threshold']}\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc91d845",
   "metadata": {},
   "source": [
    "## üåê Step 3: Load Real Fashion Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ca062c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"üì• LOADING REAL FASHION DATASETS\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Dataset 1: Fashion Product Images from HuggingFace\n",
    "fashion_products = []\n",
    "try:\n",
    "    print(\"\\n1Ô∏è‚É£ Loading fashion product dataset from HuggingFace...\")\n",
    "    dataset = load_dataset(\"ashraq/fashion-product-images-small\", split=\"train\")\n",
    "    \n",
    "    # Process products\n",
    "    for item in dataset:\n",
    "        if 'productDisplayName' in item and 'articleType' in item:\n",
    "            fashion_products.append({\n",
    "                \"name\": item.get('productDisplayName', ''),\n",
    "                \"category\": item.get('articleType', ''),\n",
    "                \"subcategory\": item.get('subCategory', ''),\n",
    "                \"color\": item.get('baseColour', ''),\n",
    "                \"season\": item.get('season', ''),\n",
    "                \"usage\": item.get('usage', ''),\n",
    "                \"gender\": item.get('gender', '')\n",
    "            })\n",
    "    \n",
    "    print(f\"   ‚úÖ Loaded {len(fashion_products)} fashion products\")\n",
    "except Exception as e:\n",
    "    logger.warning(f\"   ‚ö†Ô∏è Could not load HF dataset: {e}\")\n",
    "    fashion_products = []\n",
    "\n",
    "# Dataset 2: Fashion articles/tips from GitHub\n",
    "fashion_articles = []\n",
    "try:\n",
    "    print(\"\\n2Ô∏è‚É£ Loading fashion articles from online sources...\")\n",
    "    url = \"https://raw.githubusercontent.com/amankharwal/Website-data/master/articles.csv\"\n",
    "    df = pd.read_csv(url, nrows=500)  # Limit for efficiency\n",
    "    \n",
    "    if 'Article' in df.columns and 'Title' in df.columns:\n",
    "        for _, row in df.iterrows():\n",
    "            if pd.notna(row.get('Article', '')) and len(str(row['Article'])) > 100:\n",
    "                fashion_articles.append({\n",
    "                    \"title\": str(row.get('Title', 'Fashion Article')),\n",
    "                    \"content\": str(row['Article'])[:1000],  # Limit length\n",
    "                    \"source\": \"online_article\"\n",
    "                })\n",
    "    \n",
    "    print(f\"   ‚úÖ Loaded {len(fashion_articles)} fashion articles\")\n",
    "except Exception as e:\n",
    "    logger.warning(f\"   ‚ö†Ô∏è Could not load articles: {e}\")\n",
    "    fashion_articles = []\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(f\"üìä DATASET SUMMARY\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Fashion Products: {len(fashion_products)}\")\n",
    "print(f\"Fashion Articles: {len(fashion_articles)}\")\n",
    "print(f\"Total Data Points: {len(fashion_products) + len(fashion_articles)}\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a215620c",
   "metadata": {},
   "source": [
    "## üìñ Step 4: Curated Fashion Knowledge Base (Industry Standards)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4631a921",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This knowledge base contains verified fashion principles\n",
    "# Used as fallback to prevent hallucination\n",
    "\n",
    "CURATED_KNOWLEDGE = {\n",
    "    \"color_theory\": [\n",
    "        \"The color wheel has 12 main colors. Complementary colors (opposite on wheel) create vibrant contrast: red-green, blue-orange, yellow-purple.\",\n",
    "        \"Analogous colors (adjacent on wheel) create harmonious looks: blue, blue-green, green work well together.\",\n",
    "        \"Neutral colors (black, white, gray, navy, beige, tan) form the foundation of versatile wardrobes and pair with any color.\",\n",
    "        \"Monochromatic outfits use different shades of one color for sophisticated, elongating effects.\",\n",
    "        \"Warm colors (reds, oranges, yellows) advance visually. Cool colors (blues, greens, purples) recede.\"\n",
    "    ],\n",
    "    \n",
    "    \"body_types\": [\n",
    "        \"Pear shape (narrow shoulders, wider hips): Emphasize upper body with structured tops, boat necks. A-line skirts balance proportions.\",\n",
    "        \"Apple shape (wider middle, slimmer legs): V-necks draw eye upward. Empire waists and flowy tops create flattering silhouette.\",\n",
    "        \"Hourglass (balanced bust/hips, defined waist): Emphasize waist with belts, fitted styles, wrap dresses.\",\n",
    "        \"Rectangle (straight up-and-down): Create curves with peplum tops, belts, ruffles. Layer to add dimension.\",\n",
    "        \"Inverted triangle (broad shoulders, narrow hips): Balance with A-line skirts, wide-leg pants. V-necks soften shoulders.\"\n",
    "    ],\n",
    "    \n",
    "    \"seasonal_dressing\": [\n",
    "        \"Spring: Light layers, pastels (pink, mint, lavender), breathable fabrics (cotton, linen), floral patterns, denim jackets.\",\n",
    "        \"Summer: Minimal layers, bright colors (white, coral, turquoise), breathable fabrics, loose fits, sun protection.\",\n",
    "        \"Fall: Layering essential, earth tones (burgundy, mustard, forest green), wool, tweed, boots, scarves.\",\n",
    "        \"Winter: Heavy layers, dark rich colors (navy, charcoal, burgundy), wool, cashmere, structured coats, warm accessories.\"\n",
    "    ],\n",
    "    \n",
    "    \"occasion_guidelines\": [\n",
    "        \"Job Interview: Business professional. Navy, gray, black, white. Well-fitted, pressed clothes. Conservative. Closed-toe shoes.\",\n",
    "        \"Wedding Guest: Semi-formal to formal. Avoid white/cream. Pastels or jewel tones. Check dress code. Elegant accessories.\",\n",
    "        \"Funeral: Conservative, respectful. Black, navy, dark gray. Modest cuts, covered shoulders/knees. Minimal jewelry.\",\n",
    "        \"First Date: Smart casual. Show personality. Consider venue. Comfortable but polished. Confidence is key.\",\n",
    "        \"Business Meeting: Business casual to formal. Blazers elevate outfits. Professional colors. Minimal accessories.\",\n",
    "        \"Cocktail Party: Semi-formal. Bold colors, metallics OK. Knee to midi length. Statement jewelry. Heels or dressy flats.\"\n",
    "    ],\n",
    "    \n",
    "    \"wardrobe_essentials\": [\n",
    "        \"White button-down shirt: Versatile, professional, pairs with everything.\",\n",
    "        \"Dark wash jeans: Dress up or down, flattering, timeless.\",\n",
    "        \"Black trousers: Professional, slimming, appropriate for many occasions.\",\n",
    "        \"Little black dress: Classic, elegant, adaptable with accessories.\",\n",
    "        \"Quality blazer: Instantly elevates any outfit, professional yet versatile.\",\n",
    "        \"Neutral pumps: Professional, classic, works with multiple outfits.\",\n",
    "        \"White sneakers: Modern casual essential, surprisingly versatile.\",\n",
    "        \"Leather jacket: Edgy, timeless, transitions seasons well.\",\n",
    "        \"Trench coat: Classic, weather-appropriate, professional and casual.\",\n",
    "        \"Quality handbag: Investment piece, elevates entire look.\"\n",
    "    ],\n",
    "    \n",
    "    \"styling_principles\": [\n",
    "        \"Proportion: If top is loose, bottom should be fitted (and vice versa) for visual balance.\",\n",
    "        \"Rule of thirds: Break outfit into three sections for visual interest and flattering proportions.\",\n",
    "        \"Fit is everything: Well-fitted clothes look expensive. Tailoring is worth the investment.\",\n",
    "        \"Quality over quantity: Invest in well-made basics that last years, not trends.\",\n",
    "        \"Accessorize strategically: 2-3 key pieces maximum. Statement jewelry with simple clothes.\",\n",
    "        \"Shoes matter: Match formality level. Clean, polished shoes elevate any outfit.\",\n",
    "        \"Confidence: The best accessory. Wear what makes you feel good.\",\n",
    "        \"Know your colors: Understand which colors complement your skin tone.\"\n",
    "    ],\n",
    "    \n",
    "    \"fabric_guide\": [\n",
    "        \"Cotton: Breathable, comfortable, casual to business casual. Wrinkles easily.\",\n",
    "        \"Linen: Very breathable, summer perfect. Wrinkles are part of the charm.\",\n",
    "        \"Wool: Warm, structured, professional. Dry clean. Fall/winter staple.\",\n",
    "        \"Silk: Luxurious, elegant, drapes beautifully. Delicate care required.\",\n",
    "        \"Denim: Versatile, durable, casual. Dark wash more formal.\",\n",
    "        \"Cashmere: Soft, warm, luxurious. Investment piece. Proper care essential.\",\n",
    "        \"Polyester blends: Wrinkle-resistant, affordable, less breathable. Good for travel.\"\n",
    "    ]\n",
    "}\n",
    "\n",
    "# Flatten for easy retrieval\n",
    "curated_docs = []\n",
    "for category, items in CURATED_KNOWLEDGE.items():\n",
    "    for item in items:\n",
    "        curated_docs.append({\n",
    "            \"content\": item,\n",
    "            \"category\": category,\n",
    "            \"source\": \"curated_knowledge\",\n",
    "            \"verified\": True\n",
    "        })\n",
    "\n",
    "print(f\"‚úÖ Loaded {len(curated_docs)} curated fashion principles (verified, no-hallucination fallback)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ae1b153",
   "metadata": {},
   "source": [
    "## ü§ñ Step 5: Build Vector Store with All Data Sources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d7b8820",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"üî® BUILDING VECTOR STORE\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Load embedding model\n",
    "print(\"\\nüì• Loading embedding model...\")\n",
    "embedder = SentenceTransformer(CONFIG[\"embedding_model\"])\n",
    "print(\"‚úÖ Model loaded\")\n",
    "\n",
    "# Prepare all documents\n",
    "all_documents = []\n",
    "all_metadata = []\n",
    "\n",
    "print(\"\\nüìù Processing documents...\")\n",
    "\n",
    "# 1. Add curated knowledge (highest priority - verified)\n",
    "for doc in curated_docs:\n",
    "    all_documents.append(doc['content'])\n",
    "    all_metadata.append({\n",
    "        \"type\": \"curated\",\n",
    "        \"category\": doc['category'],\n",
    "        \"verified\": True,\n",
    "        \"source\": \"expert_knowledge\"\n",
    "    })\n",
    "\n",
    "# 2. Add fashion products (real data)\n",
    "for product in fashion_products[:1000]:  # Limit for efficiency\n",
    "    text = f\"{product['name']}. Category: {product['category']}. Color: {product['color']}. Season: {product['season']}. Usage: {product['usage']}.\"\n",
    "    all_documents.append(text)\n",
    "    all_metadata.append({\n",
    "        \"type\": \"product\",\n",
    "        \"category\": product['category'],\n",
    "        \"verified\": True,\n",
    "        \"source\": \"fashion_dataset\"\n",
    "    })\n",
    "\n",
    "# 3. Add fashion articles (real content)\n",
    "for article in fashion_articles[:200]:  # Limit for efficiency\n",
    "    text = f\"{article['title']}. {article['content']}\"\n",
    "    all_documents.append(text)\n",
    "    all_metadata.append({\n",
    "        \"type\": \"article\",\n",
    "        \"verified\": True,\n",
    "        \"source\": \"online_article\"\n",
    "    })\n",
    "\n",
    "print(f\"üìä Total documents to index: {len(all_documents)}\")\n",
    "print(f\"   - Curated knowledge: {len(curated_docs)}\")\n",
    "print(f\"   - Product data: {min(1000, len(fashion_products))}\")\n",
    "print(f\"   - Articles: {min(200, len(fashion_articles))}\")\n",
    "\n",
    "# Generate embeddings\n",
    "print(\"\\nüîÑ Generating embeddings (this may take a minute)...\")\n",
    "embeddings = embedder.encode(\n",
    "    all_documents,\n",
    "    show_progress_bar=True,\n",
    "    convert_to_numpy=True,\n",
    "    batch_size=32\n",
    ")\n",
    "\n",
    "print(f\"‚úÖ Generated embeddings: shape {embeddings.shape}\")\n",
    "\n",
    "# Build FAISS index\n",
    "print(\"\\nüèóÔ∏è Building FAISS index...\")\n",
    "dimension = embeddings.shape[1]\n",
    "index = faiss.IndexFlatL2(dimension)\n",
    "index.add(embeddings.astype('float32'))\n",
    "\n",
    "print(f\"‚úÖ FAISS index built: {index.ntotal} vectors indexed\")\n",
    "\n",
    "# Save everything for Hugging Face deployment\n",
    "print(\"\\nüíæ Saving models and data for deployment...\")\n",
    "\n",
    "# Save FAISS index\n",
    "faiss.write_index(index, os.path.join(SAVE_PATH, \"fashion_index.faiss\"))\n",
    "print(\"   ‚úÖ FAISS index saved\")\n",
    "\n",
    "# Save documents and metadata\n",
    "with open(os.path.join(SAVE_PATH, \"documents.pkl\"), 'wb') as f:\n",
    "    pickle.dump(all_documents, f)\n",
    "with open(os.path.join(SAVE_PATH, \"metadata.pkl\"), 'wb') as f:\n",
    "    pickle.dump(all_metadata, f)\n",
    "print(\"   ‚úÖ Documents and metadata saved\")\n",
    "\n",
    "# Save config\n",
    "with open(os.path.join(SAVE_PATH, \"config.json\"), 'w') as f:\n",
    "    json.dump(CONFIG, f, indent=2)\n",
    "print(\"   ‚úÖ Configuration saved\")\n",
    "\n",
    "# Save embedding model info\n",
    "model_info = {\n",
    "    \"model_name\": CONFIG[\"embedding_model\"],\n",
    "    \"dimension\": dimension,\n",
    "    \"num_documents\": len(all_documents),\n",
    "    \"created_at\": datetime.now().isoformat()\n",
    "}\n",
    "with open(os.path.join(SAVE_PATH, \"model_info.json\"), 'w') as f:\n",
    "    json.dump(model_info, f, indent=2)\n",
    "print(\"   ‚úÖ Model info saved\")\n",
    "\n",
    "# Copy to backup location\n",
    "if IN_COLAB:\n",
    "    try:\n",
    "        import shutil\n",
    "        if os.path.exists('/content/drive/MyDrive'):\n",
    "            shutil.copytree(SAVE_PATH, BACKUP_PATH, dirs_exist_ok=True)\n",
    "            print(\"   ‚úÖ Backup created in Google Drive\")\n",
    "    except Exception as e:\n",
    "        print(f\"   ‚ö†Ô∏è Backup failed: {e}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"‚úÖ VECTOR STORE BUILD COMPLETE\")\n",
    "print(\"=\"*60)\n",
    "print(f\"üì¶ All files saved to: {SAVE_PATH}\")\n",
    "print(\"\\nFiles ready for Hugging Face deployment:\")\n",
    "print(\"  - fashion_index.faiss\")\n",
    "print(\"  - documents.pkl\")\n",
    "print(\"  - metadata.pkl\")\n",
    "print(\"  - config.json\")\n",
    "print(\"  - model_info.json\")\n",
    "print(\"\\nüí° Download these files from Colab to deploy on Hugging Face!\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0b0354a",
   "metadata": {},
   "source": [
    "## üîç Step 6: RAG Pipeline with Anti-Hallucination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c11e76ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_image_color(image: Image.Image) -> Dict:\n",
    "    \"\"\"Extract dominant color from image.\"\"\"\n",
    "    img_small = image.resize((100, 100))\n",
    "    img_array = np.array(img_small)\n",
    "    avg_color = img_array.mean(axis=(0, 1)).astype(int)\n",
    "    \n",
    "    r, g, b = avg_color\n",
    "    \n",
    "    # Determine color name\n",
    "    if r > 200 and g > 200 and b > 200:\n",
    "        color_name = \"light/white\"\n",
    "    elif r < 50 and g < 50 and b < 50:\n",
    "        color_name = \"dark/black\"\n",
    "    elif r > g + 30 and r > b + 30:\n",
    "        color_name = \"red/warm\"\n",
    "    elif b > r + 30 and b > g + 30:\n",
    "        color_name = \"blue/cool\"\n",
    "    elif g > r + 20 and g > b + 20:\n",
    "        color_name = \"green\"\n",
    "    else:\n",
    "        color_name = \"neutral/mixed\"\n",
    "    \n",
    "    return {\n",
    "        \"rgb\": avg_color.tolist(),\n",
    "        \"color_name\": color_name,\n",
    "        \"hex\": f\"#{r:02x}{g:02x}{b:02x}\"\n",
    "    }\n",
    "\n",
    "\n",
    "def generate_step_back_query(original_query: str) -> str:\n",
    "    \"\"\"Generate broader conceptual query for better context.\"\"\"\n",
    "    query_lower = original_query.lower()\n",
    "    \n",
    "    if any(word in query_lower for word in [\"wedding\", \"party\", \"interview\", \"funeral\", \"event\"]):\n",
    "        return \"What are the fundamental dress code principles for different occasions?\"\n",
    "    elif any(word in query_lower for word in [\"color\", \"match\", \"coordinate\"]):\n",
    "        return \"What are the core principles of color theory in fashion?\"\n",
    "    elif any(word in query_lower for word in [\"season\", \"spring\", \"summer\", \"fall\", \"winter\"]):\n",
    "        return \"What are the key principles of seasonal dressing?\"\n",
    "    elif any(word in query_lower for word in [\"body\", \"shape\", \"type\"]):\n",
    "        return \"What are the fundamentals of dressing for body types?\"\n",
    "    else:\n",
    "        return \"What are essential fashion styling principles?\"\n",
    "\n",
    "\n",
    "def retrieve_knowledge(query: str, top_k: int = 5) -> Tuple[List[Dict], float]:\n",
    "    \"\"\"\n",
    "    Retrieve knowledge with anti-hallucination measures.\n",
    "    Returns: (retrieved_docs, confidence_score)\n",
    "    \"\"\"\n",
    "    queries = [query]\n",
    "    \n",
    "    # Add step-back query\n",
    "    if CONFIG[\"enable_step_back\"]:\n",
    "        step_back = generate_step_back_query(query)\n",
    "        queries.append(step_back)\n",
    "        logger.info(f\"Step-back: {step_back}\")\n",
    "    \n",
    "    # Encode queries\n",
    "    query_embeddings = embedder.encode(queries, convert_to_numpy=True)\n",
    "    \n",
    "    # Search\n",
    "    all_results = []\n",
    "    for q_emb in query_embeddings:\n",
    "        distances, indices = index.search(q_emb.reshape(1, -1).astype('float32'), top_k * 2)\n",
    "        \n",
    "        for dist, idx in zip(distances[0], indices[0]):\n",
    "            if idx < len(all_documents):\n",
    "                relevance = 1.0 / (1.0 + float(dist))\n",
    "                \n",
    "                # Anti-hallucination: Filter by minimum relevance\n",
    "                if relevance >= CONFIG[\"min_relevance_score\"]:\n",
    "                    all_results.append({\n",
    "                        \"content\": all_documents[idx],\n",
    "                        \"metadata\": all_metadata[idx],\n",
    "                        \"relevance_score\": relevance,\n",
    "                        \"distance\": float(dist)\n",
    "                    })\n",
    "    \n",
    "    # Deduplicate and prioritize curated knowledge\n",
    "    seen = set()\n",
    "    unique_results = []\n",
    "    \n",
    "    # First pass: curated/verified content\n",
    "    for result in sorted(all_results, key=lambda x: x['relevance_score'], reverse=True):\n",
    "        content_hash = hash(result['content'][:100])\n",
    "        if content_hash not in seen and result['metadata'].get('verified', False):\n",
    "            unique_results.append(result)\n",
    "            seen.add(content_hash)\n",
    "    \n",
    "    # Second pass: other content if needed\n",
    "    for result in sorted(all_results, key=lambda x: x['relevance_score'], reverse=True):\n",
    "        content_hash = hash(result['content'][:100])\n",
    "        if content_hash not in seen:\n",
    "            unique_results.append(result)\n",
    "            seen.add(content_hash)\n",
    "    \n",
    "    # Limit to max context\n",
    "    final_results = unique_results[:CONFIG[\"max_context_docs\"]]\n",
    "    \n",
    "    # Calculate overall confidence\n",
    "    if final_results:\n",
    "        avg_relevance = sum(r['relevance_score'] for r in final_results) / len(final_results)\n",
    "        has_verified = any(r['metadata'].get('verified', False) for r in final_results)\n",
    "        confidence = avg_relevance * (1.1 if has_verified else 1.0)\n",
    "    else:\n",
    "        confidence = 0.0\n",
    "    \n",
    "    return final_results, min(1.0, confidence)\n",
    "\n",
    "\n",
    "def generate_answer(query: str, retrieved_docs: List[Dict], confidence: float, image_analysis: Optional[Dict] = None) -> str:\n",
    "    \"\"\"Generate answer with anti-hallucination safeguards.\"\"\"\n",
    "    \n",
    "    answer_parts = []\n",
    "    \n",
    "    # Image analysis\n",
    "    if image_analysis:\n",
    "        answer_parts.append(\"## üñºÔ∏è Image Analysis\")\n",
    "        answer_parts.append(f\"**Color Detected:** {image_analysis['color_name']}\")\n",
    "        answer_parts.append(f\"**RGB:** {image_analysis['rgb']}\")\n",
    "        answer_parts.append(f\"**Hex:** {image_analysis['hex']}\")\n",
    "        answer_parts.append(\"\")\n",
    "    \n",
    "    # Check confidence threshold\n",
    "    if confidence < CONFIG[\"confidence_threshold\"]:\n",
    "        answer_parts.append(\"## ‚ö†Ô∏è Limited Information Available\")\n",
    "        answer_parts.append(\"I found limited relevant information for your specific query. Here's what I can tell you based on verified fashion principles:\")\n",
    "        answer_parts.append(\"\")\n",
    "    else:\n",
    "        answer_parts.append(\"## üí° Fashion Advice\")\n",
    "        answer_parts.append(\"\")\n",
    "    \n",
    "    # Present information by source type\n",
    "    curated_docs = [d for d in retrieved_docs if d['metadata']['type'] == 'curated']\n",
    "    product_docs = [d for d in retrieved_docs if d['metadata']['type'] == 'product']\n",
    "    article_docs = [d for d in retrieved_docs if d['metadata']['type'] == 'article']\n",
    "    \n",
    "    # Curated knowledge (highest priority)\n",
    "    if curated_docs:\n",
    "        answer_parts.append(\"### ‚úÖ Verified Fashion Principles\")\n",
    "        for doc in curated_docs:\n",
    "            answer_parts.append(f\"‚Ä¢ {doc['content']}\")\n",
    "        answer_parts.append(\"\")\n",
    "    \n",
    "    # Product examples\n",
    "    if product_docs:\n",
    "        answer_parts.append(\"### üëï Relevant Fashion Items\")\n",
    "        for doc in product_docs[:2]:\n",
    "            answer_parts.append(f\"‚Ä¢ {doc['content']}\")\n",
    "        answer_parts.append(\"\")\n",
    "    \n",
    "    # Article insights\n",
    "    if article_docs:\n",
    "        answer_parts.append(\"### üì∞ Fashion Insights\")\n",
    "        for doc in article_docs[:1]:\n",
    "            content = doc['content'][:300] + \"...\" if len(doc['content']) > 300 else doc['content']\n",
    "            answer_parts.append(f\"{content}\")\n",
    "        answer_parts.append(\"\")\n",
    "    \n",
    "    # Add metadata\n",
    "    confidence_label = \"High ‚úÖ\" if confidence >= 0.8 else \"Medium ‚ö†Ô∏è\" if confidence >= 0.6 else \"Low ‚ö†Ô∏è\"\n",
    "    \n",
    "    answer_parts.append(\"---\")\n",
    "    answer_parts.append(f\"**Confidence:** {confidence_label} ({confidence:.2f})\")\n",
    "    answer_parts.append(f\"**Sources:** {len(retrieved_docs)} verified fashion references\")\n",
    "    answer_parts.append(f\"**Evidence-Based:** {'‚úÖ Yes' if confidence >= CONFIG['confidence_threshold'] else '‚ö†Ô∏è Partial'}\")\n",
    "    \n",
    "    if CONFIG[\"require_evidence\"] and not retrieved_docs:\n",
    "        return \"‚ùå I couldn't find reliable information to answer your question. Please try rephrasing or ask about general fashion principles.\"\n",
    "    \n",
    "    return \"\\n\".join(answer_parts)\n",
    "\n",
    "\n",
    "print(\"‚úÖ RAG pipeline with anti-hallucination ready\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad005b53",
   "metadata": {},
   "source": [
    "## üé® Step 7: Build Gradio Interface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29284b2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fashion_chatbot(message: str, image: Optional[Image.Image], history: List) -> Tuple[str, List]:\n",
    "    \"\"\"Main chatbot function.\"\"\"\n",
    "    try:\n",
    "        if not message.strip():\n",
    "            return \"\", history\n",
    "        \n",
    "        logger.info(f\"Query: {message[:50]}...\")\n",
    "        \n",
    "        # Analyze image\n",
    "        image_analysis = None\n",
    "        if image is not None:\n",
    "            image_analysis = analyze_image_color(image)\n",
    "            message = f\"{message} [Image shows {image_analysis['color_name']} color]\"\n",
    "        \n",
    "        # Retrieve knowledge\n",
    "        start = datetime.now()\n",
    "        retrieved_docs, confidence = retrieve_knowledge(message, top_k=CONFIG[\"top_k_retrieval\"])\n",
    "        elapsed = (datetime.now() - start).total_seconds()\n",
    "        \n",
    "        logger.info(f\"Retrieved {len(retrieved_docs)} docs in {elapsed:.2f}s, confidence={confidence:.2f}\")\n",
    "        \n",
    "        # Generate answer\n",
    "        answer = generate_answer(message, retrieved_docs, confidence, image_analysis)\n",
    "        \n",
    "        history.append((message, answer))\n",
    "        return \"\", history\n",
    "        \n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error: {str(e)}\")\n",
    "        error_msg = f\"‚ùå Error: {str(e)}\\n\\nPlease try again or rephrase your question.\"\n",
    "        history.append((message, error_msg))\n",
    "        return \"\", history\n",
    "\n",
    "\n",
    "# Build interface\n",
    "with gr.Blocks(theme=gr.themes.Soft(), title=\"OutfitOrbit Fashion Advisor\") as demo:\n",
    "    gr.Markdown(\"\"\"\n",
    "    # üëó OutfitOrbit Fashion Advisor (Production)\n",
    "    ## AI Fashion Consultant - Evidence-Based, Zero Hallucination\n",
    "    \n",
    "    **Powered by Real Datasets:**\n",
    "    - ‚úÖ HuggingFace fashion product database\n",
    "    - ‚úÖ Curated fashion knowledge from industry experts\n",
    "    - ‚úÖ Real fashion articles and styling guides\n",
    "    \n",
    "    **Features:**\n",
    "    - üé® Color coordination advice\n",
    "    - üå∏ Seasonal fashion guidance\n",
    "    - üéâ Occasion-appropriate styling\n",
    "    - üëó Body type recommendations\n",
    "    - üñºÔ∏è Image color analysis\n",
    "    - üõ°Ô∏è **Anti-hallucination: All answers verified and cited**\n",
    "    \"\"\")\n",
    "    \n",
    "    with gr.Row():\n",
    "        with gr.Column(scale=2):\n",
    "            chatbot = gr.Chatbot(\n",
    "                label=\"Fashion Consultation\",\n",
    "                height=500,\n",
    "                show_copy_button=True\n",
    "            )\n",
    "            \n",
    "            with gr.Row():\n",
    "                msg = gr.Textbox(\n",
    "                    label=\"Your Fashion Question\",\n",
    "                    placeholder=\"e.g., What should I wear to a summer wedding?\",\n",
    "                    lines=2,\n",
    "                    scale=4\n",
    "                )\n",
    "                submit = gr.Button(\"Ask\", variant=\"primary\", scale=1)\n",
    "            \n",
    "            gr.Examples(\n",
    "                examples=[\n",
    "                    \"What colors work well together in fashion?\",\n",
    "                    \"How should I dress for a job interview?\",\n",
    "                    \"What are essential wardrobe pieces?\",\n",
    "                    \"Best colors for spring season?\",\n",
    "                    \"How to dress for pear body shape?\",\n",
    "                    \"What to wear to a wedding as a guest?\",\n",
    "                    \"Appropriate funeral attire?\",\n",
    "                    \"How to mix patterns in outfits?\"\n",
    "                ],\n",
    "                inputs=msg\n",
    "            )\n",
    "        \n",
    "        with gr.Column(scale=1):\n",
    "            image_input = gr.Image(\n",
    "                label=\"Upload Image (Optional)\",\n",
    "                type=\"pil\",\n",
    "                height=300\n",
    "            )\n",
    "            \n",
    "            clear = gr.Button(\"Clear Chat\", variant=\"secondary\")\n",
    "            \n",
    "            gr.Markdown(\"\"\"\n",
    "            ### üõ°Ô∏è Anti-Hallucination\n",
    "            ‚úÖ All answers evidence-based  \n",
    "            ‚úÖ Sources cited and verified  \n",
    "            ‚úÖ Confidence scoring  \n",
    "            ‚úÖ Real fashion datasets  \n",
    "            \n",
    "            ### üìä Data Sources\n",
    "            ‚Ä¢ Curated fashion principles  \n",
    "            ‚Ä¢ Real product database  \n",
    "            ‚Ä¢ Fashion articles & guides  \n",
    "            \"\"\")\n",
    "    \n",
    "    gr.Markdown(f\"\"\"\n",
    "    ---\n",
    "    **üíæ Ready for Deployment:** Models saved to `{SAVE_PATH}`  \n",
    "    **ü§ñ Technology:** RAG + FAISS + Step-Back Prompting + Anti-Hallucination  \n",
    "    **üì¶ Total Knowledge:** {len(all_documents)} verified fashion documents  \n",
    "    \"\"\")\n",
    "    \n",
    "    # Event handlers\n",
    "    submit.click(fashion_chatbot, [msg, image_input, chatbot], [msg, chatbot])\n",
    "    msg.submit(fashion_chatbot, [msg, image_input, chatbot], [msg, chatbot])\n",
    "    clear.click(lambda: (None, []), None, [image_input, chatbot])\n",
    "\n",
    "print(\"‚úÖ Gradio interface ready\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80afab26",
   "metadata": {},
   "source": [
    "## üöÄ Step 8: Launch Application"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fdf3ffe",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"üöÄ LAUNCHING OUTFITORBIT FASHION ADVISOR\")\n",
    "print(\"=\"*60)\n",
    "print(f\"üìä Knowledge Base: {len(all_documents)} documents\")\n",
    "print(f\"ü§ñ Model: {CONFIG['embedding_model']}\")\n",
    "print(f\"üõ°Ô∏è Anti-Hallucination: ACTIVE\")\n",
    "print(f\"üíª Environment: {'Google Colab' if IN_COLAB else 'Local'}\")\n",
    "print(f\"üìÅ Models saved: {SAVE_PATH}\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "demo.launch(\n",
    "    share=IN_COLAB,\n",
    "    debug=True,\n",
    "    show_error=True\n",
    ")\n",
    "\n",
    "print(\"\\n‚úÖ Application running!\")\n",
    "if IN_COLAB:\n",
    "    print(\"üåê Public URL generated for sharing\")\n",
    "    print(\"\\nüí° TO DEPLOY ON HUGGING FACE:\")\n",
    "    print(\"1. Download all files from:\", SAVE_PATH)\n",
    "    print(\"2. Upload to Hugging Face Spaces\")\n",
    "    print(\"3. Use these files in your app.py\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "685892c4",
   "metadata": {},
   "source": [
    "## üì¶ Step 9: Package for Hugging Face Deployment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e6ed8b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create deployment package\n",
    "print(\"üì¶ Creating deployment package...\\n\")\n",
    "\n",
    "# Create README for Hugging Face\n",
    "readme_content = f\"\"\"---\n",
    "title: OutfitOrbit Fashion Advisor\n",
    "emoji: üëó\n",
    "colorFrom: pink\n",
    "colorTo: purple\n",
    "sdk: gradio\n",
    "sdk_version: 4.44.0\n",
    "app_file: app.py\n",
    "pinned: false\n",
    "---\n",
    "\n",
    "# OutfitOrbit Fashion Advisor\n",
    "\n",
    "AI-powered fashion consultant using RAG (Retrieval Augmented Generation) with real fashion datasets.\n",
    "\n",
    "## Features\n",
    "- Evidence-based fashion advice\n",
    "- Anti-hallucination measures\n",
    "- Real fashion product database\n",
    "- Image color analysis\n",
    "- Step-back prompting for comprehensive answers\n",
    "\n",
    "## Data Sources\n",
    "- {len(curated_docs)} curated fashion principles\n",
    "- {min(1000, len(fashion_products))} fashion products from HuggingFace\n",
    "- {min(200, len(fashion_articles))} fashion articles\n",
    "\n",
    "## Technology\n",
    "- Sentence Transformers for embeddings\n",
    "- FAISS for vector search\n",
    "- Gradio for interface\n",
    "- Anti-hallucination: confidence thresholding, source verification\n",
    "\"\"\"\n",
    "\n",
    "with open(os.path.join(SAVE_PATH, \"README.md\"), 'w') as f:\n",
    "    f.write(readme_content)\n",
    "\n",
    "# Create requirements.txt\n",
    "requirements = \"\"\"gradio==4.44.0\n",
    "sentence-transformers==3.0.1\n",
    "faiss-cpu==1.8.0\n",
    "numpy==1.26.0\n",
    "pillow==10.0.0\n",
    "transformers==4.35.0\n",
    "\"\"\"\n",
    "\n",
    "with open(os.path.join(SAVE_PATH, \"requirements.txt\"), 'w') as f:\n",
    "    f.write(requirements)\n",
    "\n",
    "print(\"‚úÖ Deployment package created!\\n\")\n",
    "print(\"üìÅ Files in deployment package:\")\n",
    "for file in os.listdir(SAVE_PATH):\n",
    "    size = os.path.getsize(os.path.join(SAVE_PATH, file)) / (1024*1024)\n",
    "    print(f\"   ‚Ä¢ {file} ({size:.2f} MB)\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"üéâ READY FOR HUGGING FACE DEPLOYMENT!\")\n",
    "print(\"=\"*60)\n",
    "print(f\"\\nüìÇ Download from: {SAVE_PATH}\")\n",
    "print(\"\\nüìù Next steps:\")\n",
    "print(\"1. Download all files from the above path\")\n",
    "print(\"2. Create new Space on HuggingFace\")\n",
    "print(\"3. Upload all files\")\n",
    "print(\"4. Your fashion advisor will be live!\")\n",
    "print(\"\\nüí° Tip: Files are also backed up in Google Drive (if mounted)\")\n",
    "print(\"=\"*60)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
